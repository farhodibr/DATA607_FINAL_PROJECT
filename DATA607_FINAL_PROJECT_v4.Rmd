---
title: "DATA607 Final Project"
author: "Gillian McGovern, Aaliyah John-Harry, Farhod Ibragimov"
date: "2025-05-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Overview

For this project, we want to analyze the emotions of the top Rolling Stone's artists via sentiment analysis of song lyrics.

Data sources:

Top artists data: \* Rolling Stone Album Rankings CSV: <https://github.com/rfordatascience/tidytuesday/tree/main/data/2024/2024-05-07>

Songs data: \* Wikipedia Singles Discography (List of singles, with selected chart positions and certifications chart). Example: <https://en.wikipedia.org/wiki/The_Beatles_singles_discography>

Song Lyrics data: \* Genius API and genius.com: <https://docs.genius.com/>

## Motivation

We chose these data sets so we can:

-   Identify the emotions of songs by top artists via the lyrics
-   Explore how emotions of popular songs have changed over time
-   Explore how emotions of popular songs vary by genre

Additionally, these data sets would give us data preparation experience such as:

-   Tidying and transformation
-   API
-   Web scraping
-   MySQL

## Libraries

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(dplyr)
library(stringr)
library(rvest)
library(janitor)
library(stringr)
library(tidytext)
library(tibble)
library(textdata)
library(tidyr)
library(readr)
library(purrr)
library(forcats)
library(ggplot2)
library(doParallel)
library(foreach)
library(DBI)  
library(RMariaDB)


# Load sentiment lexicons
nrc  <- get_sentiments("nrc")
bing  <- get_sentiments("bing")

# Detect number of cores and create cluster
num_cores <- parallel::detectCores() - 1  # leave one core free
cl <- makeCluster(num_cores)
registerDoParallel(cl)
```

## Find the Top Artists

#### Read the Data

```{r echo=TRUE, message=FALSE, warning=FALSE}
rs <- read_csv("https://raw.githubusercontent.com/aaliyahmjh/DATA607Project/refs/heads/main/rolling_stone.csv", show_col_types = FALSE)
head(rs)
```

#### Tidy the Data

This data set is untidy because it has a wide structure with duplicate columns such as name and 3 separate rank columns that can be combined and referenced with a "year" column:

```{r echo=TRUE}
# Tidy the data
tidy_rs <- rs %>%
  pivot_longer(
    cols = starts_with("rank_"),    
    names_to = "year",               
    values_to = "rank",             
    names_pattern = "rank_(\\d+)" 
  )

head(tidy_rs)
```

Now each observation represents an album/year combination making the data set tidy.

#### Filter the Data

Next we want to filter the data set to only focus on albums ranked in 2020:

```{r echo=TRUE, message=FALSE, warning=FALSE}
filter_rs <- tidy_rs %>%
  select(clean_name, album, genre, year, rank)

# Filter dataset to only focus on albums ranked in 2020
filter_rs <- filter_rs %>%
  filter(year == 2020) %>%
  filter(!is.na(rank))

head(filter_rs)
```

Now we want to grab only the top 10 artists:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Select the top 10 artists & albums by rank 
top10_by_rank <- filter_rs %>%
  arrange(rank) %>%      # sort ascending
  slice_head(n = 10)      # take the first 10 rows

top10_by_rank
```

The top artists are:

-   Marvin Gaye
-   The Beach Boys
-   Joni Mitchell
-   Stevie Wonder
-   The Beatles
-   Nirvana
-   Fleetwood Mac
-   Prince
-   Bob Dylan
-   Lauryn Hill

Note: none of the top artists from Rolling Stone are recent artists, so when we look at the songs and when they were released, we'll have more data from 1960s - 1990s.

## Find the Songs for Each Artist

Now that we have our artists to focus on, next is grabbing the songs for each artist. We'll be grabbing this data from Wikipedia for us to get web scraping experience.

#### Read the Data

Each Wikipedia page is set up a bit differently, so we're going to get the songs for each artist individually:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Get the html
html_marvin_gaye <- read_html("https://en.wikipedia.org/wiki/Marvin_Gaye_discography#Singles")
html_beach_boys <- read_html("https://en.wikipedia.org/wiki/The_Beach_Boys_discography#Singles")
html_joni_mitchell <- read_html("https://en.wikipedia.org/wiki/Joni_Mitchell_discography#Singles")
html_stevie_wonder <- read_html("https://en.wikipedia.org/wiki/Stevie_Wonder_discography#Singles")
html_the_beatles <- read_html("https://en.wikipedia.org/wiki/The_Beatles_singles_discography#Singles")
html_nirvana <- read_html("https://en.wikipedia.org/wiki/Nirvana_discography#Singles")
html_fleetwood_mac <- read_html("https://en.wikipedia.org/wiki/Fleetwood_Mac_discography#Singles")
html_prince <- read_html("https://en.wikipedia.org/wiki/Prince_singles_discography#Singles")
html_bob_dylan <- read_html("https://en.wikipedia.org/wiki/Bob_Dylan_discography#Singles")
html_lauryn_hill <- read_html("https://en.wikipedia.org/wiki/Lauryn_Hill_discography#Singles")
```

Next we select the tables we want from the HTML. Note, some artist's pages have multiple tables for songs where each table represents a decade. For these artists, we'll need to gather multiple tables in order to gather all the songs:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Scrape the songs table from wikipedia
get_songs_df <- function(html, css_selector) {
  songs <- html |> html_elements(css_selector) |>
    html_table()
  return(as.data.frame(songs[[1]]))
}

# Note: these Wikipedia pages can be updated, so it's possible this code won't run in the future (css selector would need to be updated)
marvin_gaye_df <- get_songs_df(html_marvin_gaye, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(30)") # 1960s
marvin_gaye_df2 <- get_songs_df(html_marvin_gaye, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(32)") # 1970 - 1984
marvin_gaye_df3 <- get_songs_df(html_marvin_gaye, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(34)") # Posthumous
beach_boys_df <- get_songs_df(html_beach_boys, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(21)") # 1960s
beach_boys_df2 <- get_songs_df(html_beach_boys, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(23)") # 1970s
beach_boys_df3 <- get_songs_df(html_beach_boys, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(25)") # 1980s
beach_boys_df4 <- get_songs_df(html_beach_boys, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(27)") # 1990s - present
joni_mitchell_df <- get_songs_df(html_joni_mitchell, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(19)")
stevie_wonder_df <- get_songs_df(html_stevie_wonder, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(18)") # 1960s
stevie_wonder_df2 <- get_songs_df(html_stevie_wonder, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(20)") # 1970s
stevie_wonder_df3 <- get_songs_df(html_stevie_wonder, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(22)") # 1980s
stevie_wonder_df4 <- get_songs_df(html_stevie_wonder, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(24)") # 1990s - present
the_beatles_df <- get_songs_df(html_the_beatles, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(10)")
nirvana_df <- get_songs_df(html_nirvana, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(20)")
fleetwood_mac_df <- get_songs_df(html_fleetwood_mac, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(23)")
prince_df <- get_songs_df(html_prince, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(18)") # 1970s & 80s
prince_df2 <- get_songs_df(html_prince, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(20)") # 1990s
prince_df3 <- get_songs_df(html_prince, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(22)") # 2000s
prince_df4 <- get_songs_df(html_prince, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(24)") # 2010s - 20s
bob_dylan_df <- get_songs_df(html_bob_dylan, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(18)")
lauryn_hill_df <- get_songs_df(html_lauryn_hill, "#mw-content-text > div.mw-content-ltr.mw-parser-output > table:nth-child(18)")
```

#### Tidy and Prepare the Data

Next we'll go through each unique dataframe (note, each dataframe is slightly different from each other), and tidy the data. These dataframes are untidy because each chart category is a unique column. Instead there should be a general `albums_chart` category variable and a `rank` variable to represent this information.

##### Marvin Gaye

```{r echo=TRUE}
# Marvin Gaye
## 1960s ##
# Keep the important variables
marvin_gaye_df <- marvin_gaye_df[, 1:11]

# First row is actually the column names
marvin_gaye_df <- marvin_gaye_df |>
  row_to_names(row_number = 1)

# Clean up the names
marvin_gaye_df_clean <- marvin_gaye_df %>%
  clean_names()
colnames(marvin_gaye_df_clean)[4:9] <- c("us", "us_r_and_b", "can", "ire", "ned", "uk")

# Make tidy - make the albums chart it's own variable
marvin_gaye_df_clean <- marvin_gaye_df_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# Clean up
marvin_gaye_df_clean <- marvin_gaye_df_clean |>
  filter(title != '"â€”" denotes items that did not chart or were not released in that territory.')
marvin_gaye_df_clean$title <- str_extract(marvin_gaye_df_clean$title , "^(.).*\\1")
head(marvin_gaye_df_clean)

## 1970 - 1984 ##
# First row is actually the column names
marvin_gaye_df2 <- marvin_gaye_df2 |>
  row_to_names(row_number = 1)

# Clean up the names
marvin_gaye_df2_clean <- marvin_gaye_df2 %>%
  clean_names()
colnames(marvin_gaye_df2_clean)[4:12] <- c("us", "us_r_and_b", "aus", "can", "ger", "ire", "ned", "swe", "uk")

# Make tidy - make the albums chart it's own variable
marvin_gaye_df2_clean <- marvin_gaye_df2_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")
head(marvin_gaye_df2_clean)

# Clean up
marvin_gaye_df2_clean <- marvin_gaye_df2_clean |>
  filter(title != '"â€”" denotes items that did not chart or were not released in that territory.')
marvin_gaye_df2_clean$title <- str_extract(marvin_gaye_df2_clean$title , "^(.).*\\1")

## Posthumous ##
# First row is actually the column names
marvin_gaye_df3 <- marvin_gaye_df3 |>
  row_to_names(row_number = 1)

# Clean up the names
marvin_gaye_df3_clean <- marvin_gaye_df3 %>%
  clean_names()
colnames(marvin_gaye_df3_clean)[4:12] <- c("us", "us_r_and_b", "aus", "ger", "ire", "ned", "sco", "swe", "uk")

# Make tidy - make the albums chart it's own variable
marvin_gaye_df3_clean <- marvin_gaye_df3_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# Clean up
marvin_gaye_df3_clean <- marvin_gaye_df3_clean |>
  filter(title != '"â€”" denotes items that did not chart or were not released in that territory. "N/A" indicates chart not yet published.')
marvin_gaye_df3_clean$title <- str_extract(marvin_gaye_df3_clean$title , "^(.).*\\1")

head(marvin_gaye_df3_clean)
```

##### The Beach Boys

```{r echo=TRUE}
# The Beach Boys

## 1960s ##
beach_boys_df <- beach_boys_df |>
  row_to_names(row_number = 1)

# Clean up the names
beach_boys_df_clean <- beach_boys_df %>%
  clean_names()
colnames(beach_boys_df_clean)[2:12] <- c("title", "us", "us_cash_box", "us_record_world", "aus", "can", "nl", "nor", "swe", "uk", "phi")

# Make tidy - make the albums chart it's own variable
beach_boys_df_clean <- beach_boys_df_clean |>
  pivot_longer(cols = us:phi, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
beach_boys_df_clean <- separate_rows(beach_boys_df_clean, title, sep = '""')
beach_boys_df_clean

# Clean up
beach_boys_df_clean <- beach_boys_df_clean |>
  filter(title != '"â€”" denotes a release that did not chart, was not released in the country or the information is unknown (* - US Record World chart data incomplete for early 1964)')
beach_boys_df_clean$title <- str_extract(beach_boys_df_clean$title , "^(.).*\\1")

## 1970s ##
beach_boys_df2 <- beach_boys_df2 |>
  row_to_names(row_number = 1)

# Clean up the names
beach_boys_df2_clean <- beach_boys_df2 %>%
  clean_names()
colnames(beach_boys_df2_clean)[2:12] <- c("title", "us", "us_cash_box", "us_record_world", "us_ac", "aus", "can", "nl", "nor", "swe", "uk")

# Make tidy - make the albums chart it's own variable
beach_boys_df2_clean <- beach_boys_df2_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
beach_boys_df2_clean <- separate_rows(beach_boys_df2_clean, title, sep = '""')

## 1980s ##
beach_boys_df3 <- beach_boys_df3 |>
  row_to_names(row_number = 1)

# Clean up the names
beach_boys_df3_clean <- beach_boys_df3 %>%
  clean_names()
colnames(beach_boys_df3_clean)[2:9] <- c("title", "us", "us_cash_box", "us_ac", "aus", "can", "ger", "uk")

# Make tidy - make the albums chart it's own variable
beach_boys_df3_clean <- beach_boys_df3_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
beach_boys_df3_clean <- separate_rows(beach_boys_df3_clean, title, sep = '""')
beach_boys_df3_clean <- separate_rows(beach_boys_df3_clean, title, sep = '" "')

## 1990s - Present
beach_boys_df4 <- beach_boys_df4 |>
  row_to_names(row_number = 1)

# Clean up the names
beach_boys_df4_clean <- beach_boys_df4 %>%
  clean_names()
colnames(beach_boys_df4_clean)[2:10] <- c("title", "us", "us_cash_box", "us_ac", "aus", "can", "ger", "uk", "us_cou")

# Make tidy - make the albums chart it's own variable
beach_boys_df4_clean <- beach_boys_df4_clean |>
  pivot_longer(cols = us:us_cou, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
beach_boys_df4_clean <- separate_rows(beach_boys_df4_clean, title, sep = '""')
beach_boys_df4_clean <- separate_rows(beach_boys_df4_clean, title, sep = '" "')

the_beach_boys_df_clean <- beach_boys_df_clean
the_beach_boys_df2_clean <- beach_boys_df2_clean
the_beach_boys_df3_clean <- beach_boys_df3_clean
the_beach_boys_df4_clean <- beach_boys_df4_clean
head(the_beach_boys_df_clean)
head(the_beach_boys_df2_clean)
head(the_beach_boys_df3_clean)
head(the_beach_boys_df4_clean)
```

##### Joni Mitchell

```{r echo=TRUE}
# Joni Mitchell
joni_mitchell_df <- joni_mitchell_df |>
  row_to_names(row_number = 1)

# Clean up the variable names
joni_mitchell_df_clean <- joni_mitchell_df %>%
  clean_names()
colnames(joni_mitchell_df_clean)[3:9] <- c("can", "can_uc", "aus", "uk", "us", "us_ac", "us_main")

# Make tidy - make the albums chart it's own variable
joni_mitchell_df_clean <- joni_mitchell_df_clean |>
  pivot_longer(cols = can:us_main, names_to = "albums_chart", values_to = "peak_chart_position")

joni_mitchell_df_clean <- joni_mitchell_df_clean |>
  filter(title != '"â€”" denotes releases that did not chart')

# Clean up song names
joni_mitchell_df_clean$title <- str_extract(joni_mitchell_df_clean$title , "^(.).*\\1")
head(joni_mitchell_df_clean)
```

##### Stevie Wonder

```{r echo=TRUE}
# Stevie Wonder
stevie_wonder_df <- stevie_wonder_df |>
  row_to_names(row_number = 1)

# Clean up the names
stevie_wonder_df_clean <- stevie_wonder_df %>%
  clean_names()
colnames(stevie_wonder_df_clean)[1:11] <- c("title", "year", "us", "us_r_and_b", "us_ac", "bel", "can", "ger", "ire", "swi", "uk")

# Make tidy - make the albums chart it's own variable
stevie_wonder_df_clean <- stevie_wonder_df_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
stevie_wonder_df_clean <- separate_rows(stevie_wonder_df_clean, title, sep = 'b/w')
head(stevie_wonder_df_clean)


## 1970s ##
stevie_wonder_df2 <- stevie_wonder_df2 |>
  row_to_names(row_number = 1)

# Clean up the names
stevie_wonder_df2_clean <- stevie_wonder_df2 %>%
  clean_names()
colnames(stevie_wonder_df2_clean)[1:12] <- c("title", "year", "us", "us_r_and_b", "us_ac", "aus", "bel", "can", "ger", "ire", "swi", "uk")

# Make tidy - make the albums chart it's own variable
stevie_wonder_df2_clean <- stevie_wonder_df2_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
stevie_wonder_df2_clean <- separate_rows(stevie_wonder_df2_clean, title, sep = 'b/w')
head(stevie_wonder_df2_clean)

## 1980s ##
stevie_wonder_df3 <- stevie_wonder_df3 |>
  row_to_names(row_number = 1)

# Clean up the names
stevie_wonder_df3_clean <- stevie_wonder_df3 %>%
  clean_names()
colnames(stevie_wonder_df3_clean)[1:12] <- c("title", "year", "us", "us_r_and_b", "us_ac", "aus", "bel", "can", "ger", "ire", "swi", "uk")

# Make tidy - make the albums chart it's own variable
stevie_wonder_df3_clean <- stevie_wonder_df3_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
stevie_wonder_df3_clean <- separate_rows(stevie_wonder_df3_clean, title, sep = 'b/w')
head(stevie_wonder_df3_clean)

## 1990s - present ##
stevie_wonder_df4 <- stevie_wonder_df4 |>
  row_to_names(row_number = 1)

# Clean up the names
stevie_wonder_df4_clean <- stevie_wonder_df4 %>%
  clean_names()
colnames(stevie_wonder_df4_clean)[1:11] <- c("title", "year", "us", "us_r_and_b", "us_ac", "bel", "can", "ger", "ire", "swi", "uk")

# Make tidy - make the albums chart it's own variable
stevie_wonder_df4_clean <- stevie_wonder_df4_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
stevie_wonder_df4_clean <- separate_rows(stevie_wonder_df4_clean, title, sep = 'b/w')
head(stevie_wonder_df4_clean)
```

##### The Beatles

```{r echo=TRUE}
# The Beatles
the_beatles_df <- the_beatles_df |>
  row_to_names(row_number = 1)

# Clean up the names
the_beatles_df_clean <- the_beatles_df %>%
  clean_names()
colnames(the_beatles_df_clean)[1:15] <- c("title", "year", "uk", "aus", "aut", "bel", "can", "ger", "nld", "nor", "nz", "swi", "us", "us_cash_box", "us_record_world")

# Make tidy - make the albums chart it's own variable
the_beatles_df_clean <- the_beatles_df_clean |>
  pivot_longer(cols = uk:us_record_world, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
the_beatles_df_clean <- separate_rows(the_beatles_df_clean, title, sep = '""')
head(the_beatles_df_clean)
```

##### Nirvana

```{r echo=TRUE}
# Nirvana
nirvana_df <- nirvana_df |>
  row_to_names(row_number = 1)

# Clean up the names
nirvana_df_clean <- nirvana_df %>%
  clean_names()
colnames(nirvana_df_clean)[3:12] <- c("us", "aus", "bel", "fin", "fra", "ire", "nz", "prt", "swe", "uk")

# Make tidy - make the albums chart it's own variable
nirvana_df_clean <- nirvana_df_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")
head(nirvana_df_clean)
```

##### Fleetwood Mac

```{r echo=TRUE}
# Fleetwood Mac
fleetwood_mac_df <- fleetwood_mac_df |>
  row_to_names(row_number = 1)

# Clean up the names
fleetwood_mac_df_clean <- fleetwood_mac_df %>%
  clean_names()
colnames(fleetwood_mac_df_clean)[3:13] <- c("uk", "us", "us_rock", "us_ac", "aus", "can", "ger", "irl", "nl", "nz")

# Make tidy - make the albums chart it's own variable
fleetwood_mac_df_clean <- fleetwood_mac_df_clean |>
  pivot_longer(cols = uk:nz, names_to = "albums_chart", values_to = "peak_chart_position")
head(fleetwood_mac_df_clean)
```

##### Prince

```{r echo=TRUE}
# Prince

## 70s & 80s ##
prince_df <- prince_df |>
  row_to_names(row_number = 1)

# Clean up the names
prince_df_clean <- prince_df %>%
  clean_names()
colnames(prince_df_clean)[3:7] <- c("us", "us_r_and_b", "us_dance", "nld_tip", "uk")

# Make tidy - make the albums chart it's own variable
prince_df_clean <- prince_df_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")
head(prince_df_clean)

## 1990s ##
prince_df2 <- prince_df2 |>
  row_to_names(row_number = 1)

# Clean up the names
prince_df2_clean <- prince_df2 %>%
  clean_names()
colnames(prince_df2_clean)[3:12] <- c("us", "us_r_and_b", "aus", "can", "fra", "ger", "nz", "swe", "swi", "uk")

# Make tidy - make the albums chart it's own variable
prince_df2_clean <- prince_df2_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")
head(prince_df2_clean)

## 2000s ##
prince_df3 <- prince_df3 |>
  row_to_names(row_number = 1)

# Clean up the names
prince_df3_clean <- prince_df3 %>%
  clean_names()
colnames(prince_df3_clean)[3:11] <- c("us", "us_r_and_b", "aus", "ger", "ire", "nld", "nor", "swi", "uk")

# Make tidy - make the albums chart it's own variable
prince_df3_clean <- prince_df3_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")
head(prince_df3_clean)

## 2010s - present ##
prince_df4 <- prince_df4 |>
  row_to_names(row_number = 1)

# Clean up the names
prince_df4_clean <- prince_df4 %>%
  clean_names()
colnames(prince_df4_clean)[3:7] <- c("us_adult_r_and_b", "us_r_and_b", "us_r_and_b_digital", "us_r_and_b_sales", "uk")

# Make tidy - make the albums chart it's own variable
prince_df4_clean <- prince_df4_clean |>
  pivot_longer(cols = us_adult_r_and_b:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# Wikipedia added a "Posthumous" section within the same table, so need to remove that row to make the data frame tidy
prince_df4_clean <- prince_df4_clean |>
  filter(title != "Posthumous", title != '"â€”" denotes a single that was not released or did not chart in the region.')
head(prince_df4_clean)
```

##### Bob Dylan

```{r echo=TRUE}
# Bob Dylan
bob_dylan_df <- bob_dylan_df |>
  row_to_names(row_number = 1)

# Clean up the names
bob_dylan_df_clean <- bob_dylan_df %>%
  clean_names()
colnames(bob_dylan_df_clean)[2:9] <- c("title", "us", "us_main", "us_cash", "aus", "ire", "nl", "uk")

# Make tidy - make the albums chart it's own variable
bob_dylan_df_clean <- bob_dylan_df_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")

# A side and B side single appear in the same cell in single variable, so we need to break them out into individual observations
bob_dylan_df_clean <- separate_rows(bob_dylan_df_clean, title, sep = 'b/w')
head(bob_dylan_df_clean)
```

##### Lauryn Hill

```{r echo=TRUE}
# Lauryn Hill
lauryn_hill_df <- lauryn_hill_df |>
  row_to_names(row_number = 1)

# Clean up the names
lauryn_hill_df_clean <- lauryn_hill_df %>%
  clean_names()
colnames(lauryn_hill_df_clean)[3:12] <- c("us", "us_r_and_b", "us_rhy", "aus", "fra", "nl", "nz", "swe", "swi", "uk")

# Make tidy - make the albums chart it's own variable
lauryn_hill_df_clean <- lauryn_hill_df_clean |>
  pivot_longer(cols = us:uk, names_to = "albums_chart", values_to = "peak_chart_position")
head(lauryn_hill_df_clean)
```

We now have a tidy song dataframe for each artist.

## Creating a Single Dataframe for Artist/Song/Album/Year

Now let's combine all the dataframes into one called `artist_dfs`:

```{r echo=TRUE}
artist_dfs <- c(
  # Marvin Gaye
  "marvin_gaye_df_clean",
  "marvin_gaye_df2_clean",
  "marvin_gaye_df3_clean",
  
  # The Beach Boys
  "the_beach_boys_df_clean",
  "the_beach_boys_df2_clean",
  "the_beach_boys_df3_clean",
  "the_beach_boys_df4_clean",  
  
  
  # Joni Mitchell
  "joni_mitchell_df_clean",
  
  # Stevie Wonder
  "stevie_wonder_df_clean",
  "stevie_wonder_df2_clean",
  "stevie_wonder_df3_clean",
  "stevie_wonder_df4_clean",
  
  # The Beatles
  "the_beatles_df_clean",
  
  # Nirvana
  "nirvana_df_clean",
  
  # Fleetwood Mac
  "fleetwood_mac_df_clean",
  
  # Prince
  "prince_df_clean",
  "prince_df2_clean",
  "prince_df3_clean",
  "prince_df4_clean",
  
  # Bob Dylan
  "bob_dylan_df_clean",
  
  # Lauryn Hill
  "lauryn_hill_df_clean"
)

```

#### Clean the Data

Since some of the values from the song title variable are messy, let's clean the dataframe and write the dataframe to a CSV:

```{r echo=TRUE}
# This function:
# - extracts artist name from object name (everything before "_df")
# - cleans song titles
# - adds artist column
# - saves cleaned df to global env with name like "artist_cleaned_songs"

clean_and_save_songs_df <- function(df_name_string) {
  # get df by name
  df <- get(df_name_string, envir = .GlobalEnv)

  # get artist name from df name (before "_df")
  artist_id <- str_extract(df_name_string, "^(.*?)(?=_df)")
  artist_title <- str_to_title(str_replace_all(artist_id, "_", " "))

  cleaned_df <- df |>
    mutate(
      # clean title â€” remove quotes, () [] {}, cut after cd, us, uk etc.
      title = title |>
        str_trim() |>
        str_replace_all('"', "") |>
        str_remove_all("\\(.*?\\)") |>
        str_remove_all("\\[.*?\\]") |>
        str_remove_all("\\{.*?\\}") |>
        str_remove_all("(?i)[ ]?(cd|us|uk|canadian)[\\s\\-:]+.*$") |>
        str_squish(),
      # add artist column
      artist = artist_title
    ) |>
    # drop junk rows like "denotes", "not released", etc.
    filter(
      !str_detect(title, "(?i)denotes|indicates|refers to|represents|not released")
    ) |>
    # keep only one row per title
    distinct(title, .keep_all = TRUE)

  # save cleaned df to global env
  cleaned_df_name <- paste0(artist_id, "_cleaned_songs")
  assign(cleaned_df_name, cleaned_df, envir = .GlobalEnv)

  # if album/year column missing, add NA
  if (!"album" %in% names(cleaned_df)) cleaned_df$album <- NA
  if (!"year" %in% names(cleaned_df)) cleaned_df$year <- NA

  # keep only needed columns
  minimal_df <- cleaned_df |>
    select(artist, title, album, year)

  # if all_artists_songs doesnâ€™t exist, create it
  if (!exists("all_artists_songs", envir = .GlobalEnv)) {
    assign("all_artists_songs", minimal_df, envir = .GlobalEnv)
  } else {
    # if exists, add to it
    existing <- get("all_artists_songs", envir = .GlobalEnv)
    updated <- bind_rows(existing, minimal_df)
    assign("all_artists_songs", updated, envir = .GlobalEnv)
  }

  return(cleaned_df)
}


artists_songs_album <- invisible(lapply(artist_dfs, clean_and_save_songs_df))

write.csv(all_artists_songs, "all_artists_songs.csv")
all_artists_songs |>
  group_by(artist, title) |>
  filter(n() > 1) |>
  arrange(artist, title)

all_artists_songs <- all_artists_songs |>
  distinct(artist, title, .keep_all = TRUE)
all_artists_songs |>
  group_by(artist, title) |>
  filter(n() > 1) |>
  arrange(artist, title)

all_artists_songs <- all_artists_songs |>
  distinct(artist, title, .keep_all = TRUE)

head(all_artists_songs)
```

We now have a clean, tidy dataframe `all_artists_songs` which contains artist, song title, album and year data. Next we'll add on the emotion for each song.

## Creating messy SQL database from all_artists_songs and returning it as tidy df

This section is for MySQL (we wanted to include MySQL for this project). We decided to upload a messy dataframe, grab it from MySQL, then tidy it back up again:

Connecting to MySQL:

```{r eval=FALSE, echo=TRUE}
# get values securely from env
user <- Sys.getenv("MYSQL_USER")
password <- Sys.getenv("MYSQL_PASSWORD")
dbname <- Sys.getenv("MYSQL_DB")
host <- Sys.getenv("MYSQL_HOST")
port <- as.integer(Sys.getenv("MYSQL_PORT"))
print(user)

# connect to MySQL
con <- dbConnect(
  RMariaDB::MariaDB(),
   user = user,
  user = user,
  password = password,
  dbname = dbname,
  host = host,
  port = 3306,
  

)
```

Uploading messy table to MySQL:

```{r eval=FALSE, echo=TRUE}
messy_all_artists <- all_artists_songs |>
  mutate(
    song_1 = title,
    song_2 = ifelse(row_number() %% 2 == 0, paste(title, "Remix"), NA),  # some second titles
    notes = case_when(
      grepl("Remix", title) ~ "CD version",
      grepl("Love", title, ignore.case = TRUE) ~ "â€” denotes b-side",
      TRUE ~ ""
    ),
    album_name = album,
    release_year = year,
    id = row_number()  
  ) |>
  select(id, artist_name = artist, song_1, song_2, album_name, release_year, notes)


# upload messy table to MySQL
dbWriteTable(con, "messy_songs", messy_all_artists, overwrite = TRUE, row.names = FALSE)
```

Grabbing the dataframe and tidying it again:

```{r eval=FALSE, echo=TRUE}
messy_from_mysql <- dbReadTable(con, "messy_songs")

tidy_from_mysql <- messy_from_mysql |>
  filter(!is.na(artist_name)) |>
  filter(!str_detect(notes, "(?i)denotes|cd|remix")) |>
  pivot_longer(
    cols = starts_with("song_"),
    names_to = "song_slot",
    values_to = "title"
  ) |>
  # Remove missing or empty titles
  filter(!is.na(title), str_trim(title) != "") |>
  # Remove titles with remix/variation keywords
  filter(!str_detect(title, "(?i)remix|version|edit|live|instrumental|mix|b[- ]?side")) |>
  distinct(artist_name, title, .keep_all = TRUE) |>
  select(artist = artist_name, title, album = album_name, year = release_year)
write.csv(tidy_from_mysql, "tidy_from_mysql.csv")

dbDisconnect(con)
```

## Get the Song Lyrics Using Genius.com API

Next to gather song lyrics, we'll use the Genuis API. Unfortunately, the Genius API can't provide the lyrics directly, but it can provide the URL that contains the lyrics to a song. We'll then have to web scrape again to create a lyrics dataframe.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Genius API token (token needs to be keyed before submitting the project). I'll leave it as is for now.
genius_token <- "9em6wi6o9dAzPw5U_6qjYCOqRa2nQKZ26DjIe4anzXgCsJJT0hP5ZZsZK3UdsrzH"

#For example we can use this song
song_name <- "Yesterday"
artist_band <- "The Beatles"

# This function searches Genius for a song URL
search_song_final <- function(song_title, artist_name) {
  # Heads up: Best practice is to load the token securely, not hardcode it.
  # e.g., using Sys.getenv("GENIUS_API_TOKEN")
  genius_token <- "9em6wi6o9dAzPw5U_6qjYCOqRa2nQKZ26DjIe4anzXgCsJJT0hP5ZZsZK3UdsrzH" # Using hardcoded token for this example

  # Setting up to call the Genius API's search endpoint
 base_url <- "https://api.genius.com/search"
  query <- list(q = paste(song_title, artist_name))

  # Making the request to the API
  res <- GET(
    url = base_url,
    add_headers(Authorization = paste("Bearer", genius_token)), # Authorization header includes the token
    query = query
  )

  # Check if the request worked (Status 200 means OK)
  if (status_code(res) != 200) {
    warning("API request failed. Status code: ", status_code(res))
    return(NA) # Return NA on API call failure
  }

  # Now parse the JSON results. Using flatten=TRUE based on previous findings.
  content_data <- tryCatch(
      fromJSON(content(res, "text", encoding = "UTF-8"), flatten = TRUE),
      error = function(e) {
          warning("Failed to parse JSON response: ", e$message)
          return(NULL) # Return NULL on JSON parsing error
      }
  )
  # Ensure a valid response structure was received
  if (is.null(content_data) || is.null(content_data$response)) return(NA)

  # Search results are typically inside response$hits
  hits <- content_data$response$hits

  # Process the 'hits' data frame (assuming it's a data frame)
  # Handle cases with no results or if 'hits' isn't a data frame
  if (is.null(hits) || !inherits(hits, "data.frame") || nrow(hits) == 0) {
    return(NA)
  }

  # Define expected column names based on flatten=TRUE producing specific columns
  artist_col <- "result.primary_artist.name"
  url_col <- "result.url"

  # Check if the required columns exist in the data frame
  if (!all(c(artist_col, url_col) %in% names(hits))) {
     warning("Required columns ('", artist_col, "', '", url_col, "') not found in flattened API response.")
     return(NA) # Cannot proceed without these columns
  }

  # Loop through each row (each potential song hit)
  for (i in 1:nrow(hits)) {
      # Get the artist name for the current row from the flattened column
      artist_raw <- hits[[artist_col]][[i]]
      artist <- tolower(as.character(artist_raw))

      # Check if the artist name is valid and matches the search query
      if (!is.na(artist) && nzchar(artist) && str_detect(artist, fixed(tolower(artist_name)))) {
          # If the artist matched, get the URL from its column
          song_url_found <- hits[[url_col]][[i]]
          if (!is.na(song_url_found) && nzchar(song_url_found)) {
              # Match found! Return the URL and exit the function.
              return(song_url_found)
          }
      }
  }

  # If the loop finishes without returning, no suitable match was found
  return(NA)
}

# --- Example: Find the URL ---
song_url <- search_song_final(song_name, artist_band)
# This should print the found URL...
print(song_url)

```

Now we need to create functions that will get all the words for a song, `get_words_df`, and get the song emotions, `get_song_sentiments`:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Returns a dataframe where each observation is a word and the corresponding in a song
get_words_df <- function(artist_name, song_title) {
  song_url <- search_song_final(song_title, artist_name)
  if (is.na(song_url)) {
    return(NULL)
  }

  # Using the song_url found previously to scrape the lyrics

  # Only run this if a valid song_url was found
  if (!is.na(song_url) && nzchar(song_url)) {

    # Read the HTML content from the URL
    page_html <- tryCatch(
      read_html(song_url),
      error = function(e) {
        warning("Failed to read URL: ", song_url, "\nError: ", e$message)
        return(NULL) # Return NULL on page read failure
      }
    )

    # Only proceed if the webpage HTML was read successfully
    if (!is.null(page_html)) {

      # Find the part of the HTML containing the lyrics
      lyrics_selector <- "div[data-lyrics-container='true']" # Verify this selector!

      # Use rvest to find the HTML element(s) matching the selector
      lyrics_nodes <- page_html |>
        html_elements(css = lyrics_selector)

      # Check if any nodes were found using the selector
      if (length(lyrics_nodes) == 0) {
        # If not found, the selector was likely wrong or the page structure changed.
        warning("Could not find lyrics container using selector: '", lyrics_selector,
              "'. The website structure may have changed or the selector is wrong. ",
              "Please inspect the page HTML.")
        return(NULL) # Cannot proceed.
      } else {

        # Extract the text content from the found node(s)
        # html_text2 often handles line breaks better
        lyrics_text_raw <- lyrics_nodes |>
          html_text2()

        # Clean up the extracted raw text
        temp_cleaned_vector <- lyrics_text_raw %>%
          str_split("\n") %>% # Split into lines based on the newline character (\n)
          unlist() %>% # The result of str_split is a list, so unlist it
          str_remove_all("\\[[^\\]]+\\]") %>% # Remove structural markers like [Verse 1], [Chorus] etc.
          str_trim() # Remove leading/trailing whitespace from lines

        # Now, apply the filtering using standard base R subsetting (outside the pipe)
        lyrics_text_cleaned <- temp_cleaned_vector[nzchar(temp_cleaned_vector)]

        # Structure the cleaned lines into a data frame
        scraped_lyrics_df <- tibble(
          line = 1:length(lyrics_text_cleaned),
          text = lyrics_text_cleaned
        )

      }
    } else {
      # Scraping skipped because reading the URL failed earlier
      warning("Skipping scraping due to error reading URL.")
      return(NULL)
    }

  } else {
    warning("Cannot scrape lyrics because song_url was not found successfully.")
    return(NULL) # Ensure variable exists even if scraping is skipped
  }

  lyrics_df <- scraped_lyrics_df

  words <- lyrics_df %>%
    unnest_tokens(word, text)
  return(words)
}

# Returns top n song emotions for a particular song
get_song_sentiments <- function(words, artist_name, song_title, n, year = NULL) {
  null_top_emotion_df <- tibble(artist = artist_name, song = song_title, top_emotion = NA)
  
  if (is.null(words)) {
    return(null_top_emotion_df)
  }

  top_emotions_count <- words %>%
    inner_join(nrc, by = "word", relationship = "many-to-many") %>%
    filter(!sentiment %in% c("positive", "negative")) %>%
    count(sentiment, sort = TRUE) %>%
    slice_head(n = n)
  top_emotions <- top_emotions_count |>
    pull(sentiment)
  
  top_emotions_count$artist <- artist_name
  top_emotions_count$song <- song_title
  colnames(top_emotions_count)[1] <- "top_emotion"
  if (length(top_emotions) == 0) return(null_top_emotion_df)
  return(top_emotions_count)
}

# Testing
words_test <- get_words_df(artist_band, song_name)
head(words_test, 15)
scraped_lyrics_test <- get_song_sentiments(words_test, artist_band, song_name, 1)
head(scraped_lyrics_test, 15)
```

Now let's apply those functions to our tidy `artist_song_list` dataframe to create a top emotion variable:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Grab 5 songs from each of the top 10 artists
get_top5_valid_sentiments <- function(artist_name, song_titles, max_songs = 5) {
  results <- list()

  for (song in song_titles) {
    lyrics_words <- get_words_df(artist_name, song)
    res <- get_song_sentiments(lyrics_words, artist_name, song, 1)
    # keep only song + top_emotion
    if (!is.na(res$top_emotion)) {
      results <- append(results, list(
        tibble(song       = res$song,
               top_emotion = res$top_emotion)
      ))
    }

    if (length(results) >= max_songs) break
  }

  if (length(results) > 0) {
    return(bind_rows(results))
  } else {
    return(tibble(song = NA, top_emotion = NA))
  }
}

get_top5_valid_sentiments_year <- function(artist_name, title) {
  words <- get_words_df(artist_name, title)
  sent <- get_song_sentiments(words, artist_name, title, 1)
  return(sent)
}

artist_song_list <- all_artists_songs %>%
  filter(!is.na(artist), artist != "artist") %>%
  group_by(artist) %>%
  summarise(songs = list(title), .groups = "drop")

song_list_by_year <- all_artists_songs %>%
  filter(!is.na(artist), artist != "artist", year != "Source:[42]") %>%
  group_by(artist, year)

# Now apply get_top5_valid_sentiments to each row
# Use foreach to speed up the process
valid_sentiments <- foreach(i = 1:nrow(artist_song_list),
                            .combine = bind_rows,
                            .packages = c(
                              "dplyr", "purrr", "tibble", "httr", "jsonlite", 
                              "stringr", "rvest", "tidytext", "textdata", "readr", "xml2"
                            )) %dopar% {
  artist <- artist_song_list$artist[i]
  songs  <- artist_song_list$songs[[i]]
  result <- get_top5_valid_sentiments(artist, songs)
  result$artist <- artist
  result
                            }

# Final tidy dataframe
head(valid_sentiments)
```

We now have a tidy data frame, `valid_sentiments` where each observation represents a song, artist, and the top emotion for that song.

This allows for the data to be easily summarized and grouped without reshaping. We are also able to make very straightforward joins with lexicons like 'nrc' and 'bing' or other lookup tables. Tidying up this table future-proofed it with the scalability factor since we can append new columns or stack new tables if needed.


## Analysis

Now we're ready to perform our analysis. Let's look at word frequency for the top songs and analyze the emotions. Note, when looking at decades, we only look at a subset of data, and pick only one year per decade since the code runs so slowly.

```{r}
# Let's take a subset of the songs and just look at the years 1970, 1980, 1990, etc.
song_list_by_year_filtered <- song_list_by_year %>%
  filter(year %in% c("1970", "1980", "1990", "2000", "2010"))

valid_sentiments_by_decade <- foreach(i = 1:nrow(song_list_by_year_filtered), .combine = bind_rows, .packages = c("dplyr", "tibble")) %dopar% {
  artist <- song_list_by_year_filtered$artist[i]
  title  <- song_list_by_year_filtered$title[i]
  year   <- song_list_by_year_filtered$year[i]
  result <- get_top5_valid_sentiments_year(artist, title)
  if (!is.null(result) && nrow(result) > 0) {
    result$year <- year
    result
  } else {
    tibble(artist = artist, song = title, top_emotion = NA, year = year)
  }
}

valid_sentiments_by_decade <- valid_sentiments_by_decade |>
  count(year, top_emotion, sort = TRUE) |>
  group_by(year) |>
  slice_head(n = 1) |>
  ungroup()

print(valid_sentiments_by_decade)

data("stop_words")
word_freq_decade_years <- foreach(i = 1:nrow(song_list_by_year_filtered), .combine = bind_rows, .packages = c("dplyr", "tibble")) %dopar% {
  artist <- song_list_by_year_filtered$artist[i]
  title  <- song_list_by_year_filtered$title[i]
  year   <- song_list_by_year_filtered$year[i]
  result <- get_words_df(artist, title)
  if (!is.null(result) && nrow(result) > 0) {
    result$year <- year
    result
  } else {
    tibble(artist = artist, song = title, word = NA, year = year)
  }
}


word_freq_decade_years <- word_freq_decade_years |>
  anti_join(stop_words, by=c("word"="word")) %>% # don't include stop words
  filter(!(word %in% c("itâ€™s", "da", "dah", "duh", "ba", "shoo", "yeah", "ooh", "oh", "nuh", "iâ€™m", "gonna", "bop", "youâ€™re", "contributors", "lyrics", "la", "wanna"))) %>% # don't include these words in the analysis
  count(word, sort = TRUE) %>%
  slice_head(n = 10)
word_freq_decade_years
stopCluster(cl)

```

Let's graph these charts and analyze:

Word frequency:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Word Frequency
word_freq_decade_years <- word_freq_decade_years |>
  left_join(bing, by = "word", relationship = "many-to-many")

word_freq_decade_years |>
  ggplot(aes(x = reorder(word, n), y = n, fill = sentiment)) +
  geom_col() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(title = "Top 10 Words 1960 - 2010",
         x = "Word",
         y = "Count")
```

We can see here that love is the most frequent word, and is the only word that has a positive or negative emotion attached to it. For this we tried the "bing" lexicon which categorizes into either positive or negative sentiment (binary), and it could not determine a sentiment for most of these words.

Possibly the most interesting takeaway from this graph is that grandma is one of the top words.

Sentiments for each decade:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Top Emotion in Songs Per Year
valid_sentiments_by_decade |>
  ggplot(aes(x = year, y = n, fill = top_emotion)) +
  geom_col() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(title = "Top Emotion in Songs Per Year (One Year Per Decade)",
       x = "Year", y = "Count") 
```

Over time, the emotion represented for each decade is joy excluding 2000. The year 2000 had more anticipation songs than joyful.

Top Emotions in Songs by Top 10 Artists:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Top Emotions in Songs by Top 10 Artists
ggplot(valid_sentiments, aes(x = fct_infreq(top_emotion), fill = top_emotion)) +
  geom_bar() +
  coord_flip() +
  labs(title = "Top Emotions in Songs by Top 10 Artists",
       x = "Emotion", y = "Count") +
  theme_minimal()
```

This bar chart summarizes the most frequent dominant emotion detected in songs by the top 10 Rolling Stone artists.

-   Joy is by far the most common top emotion, appearing in nearly 25 songs, suggesting that uplifting and positive themes are prominent across these artists' lyrics.

-   Anticipation is the second most frequent, often associated with themes of hope, excitement, or longing.

-   Emotions like trust, anger, and fear are present but much less frequent.

-   Sadness and surprise appear rarely as the primary emotion, indicating they are less likely to be the dominant tone in top songs.

Overall, this distribution highlights the emotional leaning of popular music from legendary artists toward positive or forward-looking sentiments.

Top Emotions by Artist:

```{r echo=TRUE, message=FALSE, warning=FALSE}
valid_sentiments %>%
  group_by(artist, top_emotion) %>%
  summarise(n = n(), .groups = "drop") %>%
  arrange(artist, desc(n))

ggplot(valid_sentiments, aes(x = fct_infreq(top_emotion), fill = artist)) +
  geom_bar(position = "dodge") +
  labs(title = "Top Emotions by Artist", x = "Emotion", y = "Number of Songs") +
  theme_minimal()
```

This bar chart shows the most common emotional tone for songs by each of the top 10 Rolling Stone artists based on NRC sentiment analysis.

-   **Joy** and **anticipation** are the most dominant emotions across artists, particularly for Marvin Gaye, The Beatles, and Fleetwood Mac.

-   **Fear** and **sadness** appear most often in Lauryn Hillâ€™s songs, indicating a more emotionally intense or somber tone.

-   Bob Dylan stands out with a more diverse emotional profile that includes **anger** and **surprise**.

The chart highlights how different artists tend to gravitate toward different emotional themes in their songwriting.

Emotional Variety by Artist:

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Artists with the most emotionally varied songs
valid_sentiments %>%
  group_by(artist) %>%
  summarise(num_unique_emotions = n_distinct(top_emotion)) %>%
  arrange(desc(num_unique_emotions))
```

This chart shows us that Bob Dylan and The Beach Boys show the greatest diversity of emotions. Most artists span 2â€“3 emotions in their top 5 songs.

## Conclusions

Our analysis showed us that:

-   Joy is the most frequent emotion overall, especially in the 1970s
-   Anticipation peaks in the 1980s/90s, then sadness rises in the 2000s

Some challenges we faced were:

-   Web scraping
-   Each Wikipedia page set up differently
-   Wikipedia page updated
-   Code sometimes slow to run
-   Genius API doesn't provide song lyrics directly which added a step

Potential Future Analysis:

-   Analyze full discographies per artist
-   Compare results using multiple sentiment dictionaries
-   Explore how emotions differ by genre or rank position

## Extra Analysis

### Billbord and geniusr libraries to get more songs

Focusing on just the Rolling Stone's top artists did not provide us artists and songs from recent decades, so to expand our data, we used the `billboard` library which provides us the Billboard Top 100 songs for each year from 1960 - 2016.

#### Get the Data

Let's load `billboard`'s `wiki_hot_100s` dataframe which contains the Billboard Top 100 songs:

```{r}
library(billboard)
library(geniusr)

#Genius API
Sys.setenv(GENIUS_API_TOKEN = "9em6wi6o9dAzPw5U_6qjYCOqRa2nQKZ26DjIe4anzXgCsJJT0hP5ZZsZK3UdsrzH")
Sys.getenv("GENIUS_API_TOKEN")
?geniusr

#Creating Billboard dataframe (Includes top100 songs for each year in range of 1960 - 2016)
if (require("dplyr")) {
  data(wiki_hot_100s)
  wiki_hot_100s |>
    glimpse()
}

# This is a random sample for random 20 songs from each year
# Only look at 20 due to slow process time to obtain song lyrics
set.seed(146)
sample_billboard_1960_2016 <- wiki_hot_100s |>
  mutate(year = as.numeric(year))|>
  group_by(year) |>
  sample_n(size = 20, replace = FALSE) |> #size can be decreased to speed up the process
  ungroup()

# Grab the top 20 songs from each year
# Only look at 20 due to slow process time to obtain song lyrics
top_20_billboard_1960_2016 <- wiki_hot_100s |>
  mutate(year = as.numeric(year))|>
  group_by(year) |>
  slice_head(n = 20) |> #size can be decreased to speed up the process
  ungroup()

#this removes duplicate rows
song_jobs <- top_20_billboard_1960_2016 |>
  distinct(artist, title, year, .keep_all = TRUE)

sample_song_jobs <- sample_billboard_1960_2016 |>
  distinct(artist, title, year, .keep_all = TRUE)

head(song_jobs)
head(sample_song_jobs)
```

These dataframes, one for the top 20, and the other for a group of random 20 songs, are tidy since each observation represents a single song on the Billboard Top 100. Each cell contains a single value as well.

#### Genius API Integration

-   We tapped into the Genius API using the `geniusr` package, so that OAuth tokens, request construction, and JSON parsing all happen behind the scenes.

-   `geniusr` returns perfectly tidy data frames from nested JSON and even handles token refreshes and rateâ€‘limit retries automatically.

-   That let us pull song metadata and lyric URLs from Genius with a single function callâ€”no lowâ€‘level HTTP or manual JSON wrangling required.

Now let's add on the top emotion for each song:

```{r}
#doParallel
num_cores <- parallel::detectCores() - 1  # leave 1 core for safety
cl <- makeCluster(num_cores)
registerDoParallel(cl)


#helper function to get sentiments
get_song_emotions <- function(artist, title, n = 1) {
  words <- get_words_df(artist, title)
  sentiments <- get_song_sentiments(words, artist, title, n)
  return(sentiments)
}

#here we are getting sentiments for each song, and storing it in new df. 
#<<<______this part can take from 8 to 15 mins to complete.______>>>>>>>
songs_with_emotions <- foreach(i = 1:nrow(song_jobs), 
                               .combine = bind_rows, 
                               .packages = c("dplyr", "tibble", "purrr", "stringr", 
                                             "tidytext", "rvest", "httr", "jsonlite")) %dopar% {
  tryCatch({
    artist <- song_jobs$artist[i]
    title  <- song_jobs$title[i]
    year   <- song_jobs$year[i]
    
    sent_df <- get_song_emotions(artist, title, n = 1)
    sent_df$year <- year
    sent_df
  }, error = function(e) {
    message("Failed for ", song_jobs$title[i], " by ", song_jobs$artist[i])
    tibble(artist = song_jobs$artist[i], song = song_jobs$title[i], top_emotion = NA, year = song_jobs$year[i])
  })
                                             }

sample_songs_with_emotions <- foreach(i = 1:nrow(sample_song_jobs), 
                               .combine = bind_rows, 
                               .packages = c("dplyr", "tibble", "purrr", "stringr", 
                                             "tidytext", "rvest", "httr", "jsonlite")) %dopar% {
  tryCatch({
    artist <- sample_song_jobs$artist[i]
    title  <- sample_song_jobs$title[i]
    year   <- sample_song_jobs$year[i]
    
    sent_df <- get_song_emotions(artist, title, n = 1)
    sent_df$year <- year
    sent_df
  }, error = function(e) {
    message("Failed for ", sample_song_jobs$title[i], " by ", sample_song_jobs$artist[i])
    tibble(artist = sample_song_jobs$artist[i], song = sample_song_jobs$title[i], top_emotion = NA, year = sample_song_jobs$year[i])
  })
}


stopCluster(cl)
registerDoSEQ() 

# Final tidy dataframe

songs_with_emotions |>
  filter(is.na(top_emotion))

sample_songs_with_emotions |>
  filter(is.na(top_emotion))
head(songs_with_emotions)
head(sample_songs_with_emotions)
```

We now have tidy data frames where each observation represent a song, and it's top emotion.

#### Analysis

Now we can start our analysis. Let's see how the emotions of popular songs have changed through the years by decade:

```{r}
songs_with_emotions_grouped_by_decade <- songs_with_emotions |>
  filter(!is.na(top_emotion)) |>
  mutate(year = as.numeric(year)) |>
  group_by(decade = floor(year / 10) * 10, top_emotion)|>
  summarise(n = n(), .groups = "drop")

#charts for each decade
songs_with_emotions_grouped_by_decade |>
  ggplot(aes(x = factor(decade), y = n, fill = top_emotion)) +
  geom_col(position = "dodge") +
  labs(title = "Emotion Trends in Top 20 Billboard Song Lyrics by Decade", x = "Decade", y = "Count")

# Sampled Data
sample_songs_with_emotions_grouped_by_decade <- sample_songs_with_emotions |>
  filter(!is.na(top_emotion)) |>
  mutate(year = as.numeric(year)) |>
  group_by(decade = floor(year / 10) * 10, top_emotion)|>
  summarise(n = n(), .groups = "drop")

#charts for each decade
sample_songs_with_emotions_grouped_by_decade |>
  ggplot(aes(x = factor(decade), y = n, fill = top_emotion)) +
  geom_col(position = "dodge") +
  labs(title = "Emotion Trends in Sampled Billboard Song Lyrics by Decade", x = "Decade", y = "Count")
```

Top 20 Songs:

Looking at the count bar graph, Joy is still by far the most common top emotion, appearing in nearly 25 songs. Yet, the count gets much small after the 90s. This makes sense because the data we have access to only goes up to 2016, so the 2010 would have less data. For the 2000s decade, it's possible for some reason we could not find the lyrics to the songs, or a top emotion could not be specified.

Sampled:

Joy is still the top emotion for random sampled data. It looks like sampled data has the same issue.

Let's check where the missing emotions are:

```{r}
songs_with_emotions |>
  filter(is.na(top_emotion)) |>
  group_by(decade = floor(year / 10) * 10) |>
  summarise(total = n())

sample_songs_with_emotions |>
  filter(is.na(top_emotion)) |>
  group_by(decade = floor(year / 10) * 10) |>
  summarise(total = n())
```

As you can see, the decade with the most missing emotions is the 2000s decade. If we were doing further analysis with more time, we could pinpoint exactly why this data is missing. The sampled data has a bit less missing values in the 2000s.

Let's make another percentage graph to look at the proportions:

```{r}
# Emotion Trends in Billboard Lyrics by Decade
# Focus on percentage
songs_with_emotions_grouped_by_decade_pct <- songs_with_emotions_grouped_by_decade |>
  group_by(decade) |>
  mutate(percent = n / sum(n)) |>
  ungroup()

songs_with_emotions_grouped_by_decade_pct |>
  ggplot(aes(x = factor(decade), y = percent, fill = top_emotion)) +
  geom_col(position = "dodge") +
  labs(title = "Emotion Trends in Top 20 Billboard Song Lyrics by Decade", x = "Decade", y = "Percentage")

# Sampled Data
sample_songs_with_emotions_grouped_by_decade_pct <- sample_songs_with_emotions_grouped_by_decade |>
  group_by(decade) |>
  mutate(percent = n / sum(n)) |>
  ungroup()

sample_songs_with_emotions_grouped_by_decade_pct |>
  ggplot(aes(x = factor(decade), y = percent, fill = top_emotion)) +
  geom_col(position = "dodge") +
  labs(title = "Proportions Of Emotion Trends in Sampled Billboard Song Lyrics by Decade", x = "Decade", y = "Percentage")
```

Top 20 Songs:

This graph looks a lot more stabilized. This graph still shows Joy as the top emotion for each decade, yet this percentage decreases in the 2000s. We can also see that Anger percentage increases in the 2000s, then drops in the 2010s. This makes one wonder if world events occurring the 2000s changed overall population sentiment, which is shown in the art/music that was released during that time. Joy showed the highest percentage in 90s. Additionally, Trust decreases in the 90s and 2000s, then increases again in the 2010 decade.

Sampled:

The sampled data shows pretty similar results. Anticpation decreases over the decades, and fear has a lower percentage in the 2010s. Trust remains a bit more constant over the decades compared to the top 20 songs.

Now let's look at overall Positive vs Negative emotions, and how they've changed over time:

```{r}
# Positive vs. Negative Emotional Trends Over Time
songs_with_emotions_polarity <- songs_with_emotions |>
  filter(!is.na(top_emotion)) |>
  mutate(polarity = case_when(
    top_emotion %in% c("joy", "trust", "anticipation") ~ "Positive",
    top_emotion %in% c("sadness", "anger", "fear", "disgust") ~ "Negative",
    TRUE ~ "Neutral"
  ))

songs_with_emotions_polarity |>
  count(year, polarity) |>
  group_by(year) |>
  mutate(prop = n / sum(n)) |>
  ggplot(aes(x = as.numeric(year), y = prop, color = polarity)) +
  geom_line(size = 1.2) +
  labs(title = "Positive vs. Negative Emotional Trends Over Time (Top 20 Songs per Year)",
       x = "Year", y = "Proportion of Songs") +
  theme_minimal(base_size = 14)

# Sampled Data
sample_songs_with_emotions_polarity <- sample_songs_with_emotions |>
  filter(!is.na(top_emotion)) |>
  mutate(polarity = case_when(
    top_emotion %in% c("joy", "trust", "anticipation") ~ "Positive",
    top_emotion %in% c("sadness", "anger", "fear", "disgust") ~ "Negative",
    TRUE ~ "Neutral"
  ))

sample_songs_with_emotions_polarity |>
  count(year, polarity) |>
  group_by(year) |>
  mutate(prop = n / sum(n)) |>
  ggplot(aes(x = as.numeric(year), y = prop, color = polarity)) +
  geom_line(size = 1.2) +
  labs(title = "Positive vs. Negative Emotional Trends Over Time (Sampled Data)",
       x = "Year", y = "Proportion of Songs") +
  theme_minimal(base_size = 14)

```

Top 20 songs:

Overall there's no major trend shown in this graph, but we can see in the 2000s positive emotions decreased, while negative emotions increased surpassing positive. This corresponds with our bar graph data. Also, neutral songs do not appear in the 2010s.

Sampled:

Overall the sampled data looks very similar to the top 20 songs.

### Extra Analysis Conclusions

This analysis showed us that:

-   Joy is the most frequent emotion overall
-   Anticipation consistently takes up the 2nd highest percentage of emotions
-   Joy decreased while Anger increased in the 2000s
-   The major change in positive vs negative trend was in the 2000s where negative emotions were higher than positive
